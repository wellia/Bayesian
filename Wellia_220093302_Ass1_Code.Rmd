##################################
# Student Name: Wellia Lioeng
# Student Id: 220093302
# SIT 743 - Bayesian Assignment 1
##################################


```{r set-options, echo=FALSE, cache=FALSE}
options(width=300)
```

Q 1)

```{r}
#load data as matrix
the.data <- as.matrix(read.csv("AIMSHeronIslandData.csv", header = TRUE, sep = ","))

# generate 200 samples, the output is double
my.data <- the.data [sample(1: 366, 200), c(1:5)]

file_name <- 'Wellia-220093302-HIMyData.txt'

#write.table(my.data,file_name)  # only write once, otherwise data is changed by sampling

my.data <- read.table(file_name) # comment this out if file is not exist
my.data

humidity <- my.data[,5] # humidity is 5th column

head(humidity)
```

1.1 ) The distribution of Humidity

```{r}

hist(humidity, xlab="humidity", main="Humidity in percentage")

# box plot for the ‘Humidity’ variable. Provide a five number
res <- boxplot(humidity, xlab="humidity", main="Humidity in percentage")
res

summary(humidity)

```
1.3 Correlation Air temperature and Water temperature


```{r}

# run this line to ensure the column index for air and water temperature is correct
#head(my.data)

x = my.data[,3] # air temperature
y = my.data[,1] # water temperature

# Scatterplot air temperature and water temperature

plot(x,y, xlab="Air temperature (in celcius)", ylab="Water temperature at 1.6m depth (in celcius)", main="Water temperature and Air temperature")

# Correlation
co <- cor(x,y)
sprintf('Correlation: %f', co)

# Coefficient Determination
coeOfDet = cor(x,y)^2*100  # in percentage
sprintf('Coefficient: %f', coeOfDet)

#linear regression line
lm(y~x)
abline(lm(y~x), col="blue")
```
1.4

```{r}
# 1.4

my.data.bucketing <- my.data # reset data before bucketing

compute.bucketing <- function(my_data){

  data_len = length(my_data[,4])

  WaterTBucket = array(0,data_len)
  WindSBucket = array(0,data_len)
  AirPreBucket = array(0,data_len)

  for (i in 1:data_len){
    # water temperature
    if(my_data[i,1] > 25){
      WaterTBucket[i] <- 'high_water'
    }
    else {
      WaterTBucket[i] <- 'low_water'
    }

    # wind speed
    if(my_data[i,2] > 30){
      WindSBucket[i] <- 'high_wind'
    }
    else {
      WindSBucket[i] <- 'low_wind'
    }

    # air pressure
    if(my_data[i,4] > 1019){
      AirPreBucket[i] <- 'high_air'
      if(my_data[i,4] == '1024.4882') {
        print('hi')
      }
    }
    else {
      if(my_data[i,4] == '1024.4882') {
        print('hi2')
      }
      AirPreBucket[i] <- 'low_air'
    }
  }
  print(unique(AirPreBucket))
  cbind(WaterTBucket, WindSBucket, AirPreBucket)
}

my.data.bucketing <- cbind(my.data.bucketing, compute.bucketing(my.data))

head(my.data.bucketing)

```


```{r}
# contigency table
library ( expss )
water <- my.data.bucketing[,'WaterTBucket']
wind <- my.data.bucketing[,'WindSBucket']
air <- my.data.bucketing[,'AirPreBucket']
cro(water, wind, air)

```

Q 2

```{r}
r <- 4
w <- 6
total <- r + w

# first possiblity, first trial is red, second trial is white
# p(r).p(w)
pr <- r/total
message('pr:', pr)

r <- r + 1
total <- r + w
pw <- w/total
message('pw:', pw)

p1 <- pr * pw
message('p1:', p1)

# second possibility, first trial is white, second trial is red
# p(w).p(r)

r <- 4
w <- 6
total <- r + w
pw <- w/total
message('pw:', pw)
w <- w + 2
total <- r + w
pr <- r / total
message('pr:', pr)
p2 <- pw * pr
message('p2:',p2)

# so possibility 
# p(first or second) = p(r and w) + p(w and r)
message('p:', p1 + p2)

```

3.2.b

```{r}
#mean = b/(a-1)
#mode = b/(a+1)

a0 = 1.2
b0 = 2
x = c()
x <- c(6, 10, 12, 5, 9)
s = sum(x)
n = length(x)

a1 <- a0 + n 
b1 <- b0 + s

me <- b1/(a1 - 1)
mo <- b1/(a1 + 1)

sprintf('a1:%g', a1)
sprintf('b1:%g', b1)

sprintf('mean:%f', round(me, 2))
sprintf('mode:%f', round(mo, 2))

```

3.2.c

```{r}

library(invgamma)

colors <- c("black", "blue", "red")
labels <- c("prior (a=1.2, b=2)", "likelihood (mean=8.4)", "posterior (a=6.2, b=44)")

#prior is a inverse gamma with shape or a = 1.2, scale or b=2
a0 <- 1.2
b0 <- 2
s <- seq(0, 15, .1)
x <- c(6, 10, 12, 5, 9)
n <- length(x)
priorTheta <- dinvgamma(s, a0, b0)

# plot posterior
plot(s, priorTheta, type="n", xlab="", ylab="", main="Bayesian estimation", axes=TRUE)
lines(s, priorTheta, lwd=2, col=colors[1])

# exponential likelihood
average <- mean(x)
rate <- 1/average
print(average)
dat <- dexp(s, rate=rate)

# posterior beta
a1 <- a0 + n #6.2
b1 <- b0 + sum(x) #10.4
print(a1)
print(b1)
posTheta <- dinvgamma(s, a1, b1)

# plot likelihood
lines(s, dat, lwd=2, col=colors[2])

# plot posterior
lines(s, posTheta, lwd=2, col=colors[3])

# Add a legend
legend("topright", legend=labels, col=colors, lty=1, cex=0.8)

```


4.b


```{r}
## observations 
average_x <- 2.5
sd_likelihood <- 0.2
mean_prior <- 3
sd_prior <- 1
n <- 100
var_prior <- sd_prior ^ 2
cat(paste('prior var:',var_prior,'\n'))
var_likelihood <- sd_likelihood ^ 2
cat(paste('likelihood var:', var_likelihood,'\n'))

var_post <- 1/((1/var_prior)+(n/var_likelihood))
mean_post <- var_post*((n*average_x/var_likelihood)+(mean_prior/var_prior))
cat(paste('post var:',var_post,'\n'))
cat(paste('post sd:',round(sqrt(var_post), 2),'\n'))
cat(paste('post mean:',round(mean_post,2)))
```
4.c trapezoidal

```{r}
sd_likelihood <- 0.2

## observations 
x = 2.5

#mu values
mu = seq(1, 5, by = 0.1)

#define the trapezoidal prior
mu.prior = rep(0, length(mu)) #replicate
mu.prior[mu<=2] = -1 / 5 + mu[mu<=2] /5
mu.prior[mu>2 & mu<=3] = -3/5 + mu[mu>2 & mu<=3] * 2/5
mu.prior[mu>3 & mu<=4] = 9/5 - mu[mu>3 & mu<=4] * 2/5
mu.prior[mu>4] = 1 - mu[mu > 4] /5

#find posterior
results = normgcp(x,sd_likelihood, density = "user", mu = mu, mu.prior = mu.prior)

#plot prior, likelihood and posterior on a single plot
plot(results, overlay = TRUE, which = 1:3)
#plot the above results (prior, likelihood. posterior) in different axes
decomp(results)
#Finding the posterior mean and standard deviation for the above.
## find the posterior mean and std. deviation for the above
cat(paste('Posterior mean:', round(mean(results),2),'\n'))

```

Q 5.1

```{r}
zz<-read.table("ITdata.txt")
x<-as.matrix(zz)

k <- 5

(cl <- kmeans(x, k, nstart = 25))
plot(x, col = cl$cluster)
points(cl$centers, col = 1:6, pch = 3)

#run for several k value and save total within sum of squares
totwss = array(,c(20,1))
for (i in 2:20)
{
  print(i)
  totwss[i,1]=(kmeans(x,centers=i))$tot.withinss
  print(totwss[i])
}
plot(totwss, main="total within sum of squres (totWSS) with different K value")
totwss
```

Q 5.2 Spectral

a) create a dataset as given below and plot them
```{r}
zz<-read.table("ITdata.txt")
x<-as.matrix(zz)

#question scale or not scale
plot(x)
```

b) compute similarity matrix

```{r}
dXX<-as.matrix(dist(x)) # compute Euclidean distance between data points


AffMat<-function(S,k) #S-distance matrix and k-no of neighbours
{
  AM <- matrix(0,nrow=nrow(S),ncol=ncol(S))
  for(i in 1:nrow(S)){
    d <- sort(S[i,],decreasing=TRUE)
    for (t in 1:ncol(S))
    {
      if (S[i,t] < d[k])
      {
       AM[i,t]<-0
       AM[t,i]<-0
      } else {
       AM[i,t] <- S[i,t]
       AM[t,i] <- AM[i,t] 
      }
    }
  }
  AM
}

```


```{r}

set.seed(1000)

cParam = 0.1 # parameter of similarity function
S<-exp(-dXX/cParam) #compute similarity matrix

# find the best kval
for (kval in 11:14) {

  A<-AffMat(S,kval)
  
  # Degree of affinity matrix
  D <- diag(apply(A, 1, sum)) # sum rows
  
  L <- D - A
  
  # find eigen value and eigen vector 
  
  eigL<-eigen(L)
  
  k<-5
  Z<- eigL$vectors[,(ncol(eigL$vectors)-k+1):ncol(eigL$vectors)]
  
  km <- kmeans(Z, centers=k, nstart=5)
  
  plot(x, col=km$cluster)
}

```

6.1

```{r}
the.data <- as.matrix(read.csv("AIMSHeronIslandData.csv", header = TRUE, sep = ","))
water_temperature <- the.data[,1] # water temperature is 1st column
hist(water_temperature, xlab="water temperature (in celcius)", main="Water temperature in at 1.6 depth")
summary(water_temperature)
std <- sd(water_temperature)
m <- mean(water_temperature)
```
6.2

```{r}
h <- hist(water_temperature, col = "gray", xlab = "Water temperature in celcius", main = "Water temperature at 1.6 depth") 

m = mean(water_temperature) 
std = sd(water_temperature)
sprintf('Mean:%g', round(m,2))
sprintf('Standard deviation:%g', round(std,2))

xfit <- seq(min(water_temperature) - 1, max(water_temperature) + 1, length = 60) 
yfit <- dnorm(xfit, mean = m, sd = std)
yfit <- yfit * diff(h$mids[1:2]) * length(water_temperature) 

lines(xfit, yfit, col = "red", lwd = 2)
```
6.3

```{r}

library(mixtools)
#Gaussian mixture
mixmdl = normalmixEM(water_temperature,k=2) # k components
mixmdl
summary(mixmdl)
plot(mixmdl,which=2)
#plot(mixmdl, density = TRUE, w = 1.1)
mixmdl$lambda
mixmdl$mu
mixmdl$sigma
mixmdl$loglik

#plotting the combined curve
x1 <- seq(min(water_temperature),max(water_temperature),length=10000)
y = array(0,c(10000,length(mixmdl$lambda)))
for (i in (1:length(mixmdl$lambda)))
{
y[,i] <- dnorm(x1,mean=mixmdl$mu[i], sd=mixmdl$sigma[i])
}
ycomb=array(0,c(10000,1))
for (j in 1:length(mixmdl$lambda))
{
ycomb[,1]<-ycomb[,1] + mixmdl$lambda[j]*y[,j]
}
lines(x1,ycomb, col="black", lwd=2, type="l", lty=2)
```
6.4

```{r}
#################
#plot log likelihood
plot(mixmdl$all.loglik)
plot(mixmdl,which=1)
##########################
```

7.a.iV

```{r}
par(mar = rep(2, 4))

calculate_posterior <- function(m, n, max_x, title){
  #define a variable theta for plotting
  theta = seq(0, 1, length=1000000) #prepare 1000000 points

  prior_a <- 1
  prior_b <- 1
  
  # NSW
  a <- m + prior_a
  b <- n - m + prior_b
  
  xlimC<-c(0, max_x) #plot the range of the beta distribution 

  #plot the beta distribtion
  plot(theta, dbeta(theta, a, b), ylab="density", lwd=4, type ="l", col=2, xlim=xlimC, yaxt="n", 
       main=title)
  
  #obtain summary statistics (median, 95% credible interval)
  x<-rbeta(1000000, a, b) #randomly draw 1 million
  q <- quantile(x, c(0.025, 0.50, 0.975))
  cat(paste("posterior beta:", a, ",", b, "\n"))
  cat(paste(round(q[2]*100, 2), "(",round(q[1]*100, 2), "-", round(q[3]*100,2), ")\n"))
}

calculate_posterior(54, 5418, 0.03, "The posterior probability densities of the infection fatality rate in NSW")
calculate_posterior(820, 20507, 0.1, "The posterior probability densities of the infection fatality rate in VIC")

```


